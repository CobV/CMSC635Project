{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9612ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Wed Mar  8 12:04:48 2023\n",
    "@author: Ahmad Al Musawi\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cbe7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(df, cols):\n",
    "    '''split the dataframe into predicting table and labels\n",
    "       df: given dataset\n",
    "       cols: list of labels\n",
    "    '''\n",
    "    return df[[i for i in df if i not in cols]], df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0755103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearSVM(X_train,y_train, X_test):\n",
    "    clf = LinearSVC(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.decision_function(X_test)\n",
    "\n",
    "def GaussianSVM(X_train,y_train, X_test):\n",
    "#     print('implementing SVM...')\n",
    "    clf = SVC(kernel='rbf', C=1.0) # Gaussian radial basis function (RBF) kernel\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def PolySVM(X_train,y_train, X_test):\n",
    "#     print('implementing SVM...')\n",
    "    clf = SVC(kernel='poly', degree=2, coef0=1, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def SigmoidSVM(X_train,y_train, X_test):\n",
    "#     print('implementing SVM...')\n",
    "    clf = SVC(kernel='sigmoid', gamma='scale', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def NaiveBayes(X_train,y_train, X_test):\n",
    "#     print('implementing Naive Bayes...')\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def Logistic(X_train,y_train, X_test):\n",
    "#     print('implementing Logistic Regression...')\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions on the test set\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "   \n",
    "def CART(X_train,y_train, X_test):\n",
    "#     print('implementing CART...')\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return y_pred, clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def kNN(X_train,y_train, X_test):\n",
    "#     print('implementing kNN...')\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    # assuming X is your data and k is the number of clusters\n",
    "    clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test), clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2387180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_split(X, Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test \n",
    "\n",
    "def get_classification_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    num_classes = cm.shape[0]\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i,i]\n",
    "        fn = np.sum(cm[i,:]) - tp\n",
    "        fp = np.sum(cm[:,i]) - tp\n",
    "        tn = np.sum(cm) - tp - fp - fn\n",
    "        \n",
    "        sensitivity_i = tp / (tp + fn)\n",
    "        specificity_i = tn / (tn + fp)\n",
    "        sensitivity.append(sensitivity_i)\n",
    "        specificity.append(specificity_i)\n",
    "    \n",
    "    macro_sensitivity = np.mean(sensitivity)\n",
    "    macro_specificity = np.mean(specificity)\n",
    "    \n",
    "    return accuracy, macro_sensitivity, macro_specificity\n",
    "\n",
    "def predict(X,Y):\n",
    "    X_train, X_test, y_train, y_test = one_split(X, Y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    pred_Y = [pred(X_train,y_train, X_test) for pred in predictors]\n",
    "    return [get_classification_metrics(y_test, p) for p in pred_Y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f6947",
   "metadata": {},
   "source": [
    "# Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ecead60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    # calculate the IQR for each column\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df_clean = pd.DataFrame()\n",
    "    for col in df.columns:\n",
    "        lower = Q1[col] - 1.5 * IQR[col]\n",
    "        upper = Q3[col] + 1.5 * IQR[col]\n",
    "        df_clean[col] = df[(df[col] >= lower) & (df[col] <= upper)][col]\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9bf3d9",
   "metadata": {},
   "source": [
    "# Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009a1125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "def data_imputation(X):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    imputer.fit(X)\n",
    "    X_imputed = pd.DataFrame(imputer.transform(X), columns=X.columns)\n",
    "    return X_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2d2f17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = remove_outliers(df1)\n",
    "# df1 = data_imputation(df1)\n",
    "\n",
    "# df2 = remove_outliers(df2)\n",
    "# df2 = data_imputation(df2)\n",
    "\n",
    "# df1 = pd.read_excel('cleveland data.xlsx')\n",
    "df1 = pd.read_csv('heart.csv')\n",
    "\n",
    "# Preprocessing\n",
    "dataset = df1\n",
    "from pandas import get_dummies\n",
    "a = pd.get_dummies(dataset['sex'], prefix = \"sex\")\n",
    "b = pd.get_dummies(dataset['cp'], prefix = \"cp\")\n",
    "c = pd.get_dummies(dataset['fbs'], prefix = \"fbs\")\n",
    "d = pd.get_dummies(dataset['restecg'], prefix = \"restecg\")\n",
    "e = pd.get_dummies(dataset['exang'], prefix = \"exang\")\n",
    "f = pd.get_dummies(dataset['slope'], prefix = \"slope\")\n",
    "g = pd.get_dummies(dataset['ca'], prefix = \"ca\")\n",
    "h = pd.get_dummies(dataset['thal'], prefix = \"thal\")\n",
    "\n",
    "frames = [dataset, a, b, c, d, e, f, g, h]\n",
    "dataset2 = pd.concat(frames, axis = 1)\n",
    "dataset2 = dataset2.drop(columns = ['sex','cp', 'fbs', 'restecg','exang','slope','ca','thal'])\n",
    "\n",
    "df1 = dataset2\n",
    "X1, Y1 = split_labels(df1, ['target'])\n",
    "\n",
    "# nX1 = stats.zscore(X1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31ececaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file into a DataFrame\n",
    "# df1 = pd.read_csv('processed.cleveland.data', delimiter=',', header=None)\n",
    "# df1 = pd.read_excel('cleveland data.xlsx')\n",
    "\n",
    "df2 = pd.read_excel('CTG.xls', sheet_name = 'Raw Data')\n",
    "\n",
    "df2 = df2[[i for i in df2 if i not in ['FileName','Date','SegFile']]]\n",
    "\n",
    "X2, Y2 = split_labels(df2, ['NSP'])\n",
    "\n",
    "nX2 = stats.zscore(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4b52907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\Documents\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Documents\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9972\\2481164138.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictorsTXT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LinearSVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GaussianSVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PolySVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SigmoidSVM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NaiveBayes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Logistic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CART'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kNN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mresults1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mresults2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9972\\2663264852.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mpred_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_classification_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_Y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9972\\2663264852.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mpred_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_classification_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_Y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9972\\1583757490.py\u001b[0m in \u001b[0;36mGaussianSVM\u001b[1;34m(X_train, y_train, X_test)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mPolySVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, owner)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m# delegate only on instances, not the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# this is to allow access to the docstrings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mattr_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[1;34m\"predict_proba is not available when  probability=False\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# predictors = [ NaiveBayes, Logistic, CART, kNN]\n",
    "# predictorsTXT = ['NaiveBayes', 'Logistic', 'CART', 'kNN']\n",
    "predictors = [LinearSVM, GaussianSVM, PolySVM, SigmoidSVM, NaiveBayes, Logistic, CART, kNN]\n",
    "predictorsTXT = ['LinearSVM', 'GaussianSVM', 'PolySVM', 'SigmoidSVM', 'NaiveBayes', 'Logistic', 'CART', 'kNN']\n",
    "\n",
    "results1 = predict(X1, Y1)\n",
    "results2 = predict(X2, Y2)\n",
    "\n",
    "print('Heart Disease')\n",
    "acc, sen, spe  = [],[],[]\n",
    "for a, s, e in results1:\n",
    "    acc.append(a)\n",
    "    sen.append(s)\n",
    "    spe.append(e)\n",
    "print(pd.DataFrame({'model': predictorsTXT,'accuracy': acc, 'sensitivity': sen, 'specificity': spe, 'AUC-ROC': roc, 'AUC-PR': pr}))\n",
    "\n",
    "\n",
    "print('Heart Disease2')\n",
    "acc, sen, spe = [],[],[]\n",
    "for a, s, e  in results2:\n",
    "    acc.append(a)\n",
    "    sen.append(s)\n",
    "    spe.append(e)\n",
    "print(pd.DataFrame({'model': predictorsTXT,'accuracy': acc, 'sensitivity': sen, 'specificity': spe}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e1e673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_model(X, y=None, n = 2):\n",
    "#     print(\"PCA model\")\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    selected_features = pca.components_\n",
    "    print(f'PCA\\tNoF = {len(selected_features)}')\n",
    "    return X_pca\n",
    "\n",
    "def Kernel_PCA(X, y=None, n = 2):\n",
    "    from sklearn.decomposition import KernelPCA\n",
    "#     print(\"Kernal PCA model\")\n",
    "    pca = KernelPCA(n_components=n, kernel='rbf')\n",
    "    pca.fit_transform(X)\n",
    "    return pca\n",
    "\n",
    "def CE_Model(X, y=None, n=2):\n",
    "#     print('CE Model')\n",
    "    embedding = SpectralEmbedding(n_components=n)\n",
    "    X_CE = embedding.fit_transform(X)\n",
    "    print(f'CE\\tOld shape = {X.shape}\\t\\t new shape = {X_CE.shape}\\t\\t components = {n}')\n",
    "    return X_CE\n",
    "\n",
    "def CE2(X, y=None, n=2):\n",
    "#     print('CE Model: Laplacian Eigenmaps')\n",
    "    embedding = SpectralEmbedding(n_components=n, affinity='nearest_neighbors', n_neighbors=10, eigen_solver='arpack')\n",
    "    X_CE = embedding.fit_transform(X)\n",
    "    print(f'CE2\\tOld shape = {X.shape}\\t\\t new shape = {X_CE.shape}\\t\\t components = {n}')\n",
    "    return X_CE\n",
    "\n",
    "def LLE(X, y=None, n=2):\n",
    "    from sklearn.manifold import LocallyLinearEmbedding\n",
    "#     print('CE Model: Locally Linear Embedding')\n",
    "    embedding = LocallyLinearEmbedding(n_components=n, n_neighbors=10)\n",
    "    X_CE = embedding.fit_transform(X)\n",
    "    print(f'LLE\\tOld shape = {X.shape}\\t\\t new shape = {X_CE.shape}\\t\\t components = {n}')\n",
    "    return X_CE\n",
    "\n",
    "def Isomap(X, y=None, n=2):\n",
    "    from sklearn.manifold import Isomap\n",
    "#     print('CE Model: Isomap')\n",
    "    embedding =  Isomap(n_components=n, n_neighbors=10)\n",
    "    X_CE = embedding.fit_transform(X)\n",
    "    print(f'ISOMAP\\tOld shape = {X.shape}\\t\\t new shape = {X_CE.shape}\\t\\t components = {n}')\n",
    "    return X_CE\n",
    "\n",
    "def TSNE(X, y=None, n=2):\n",
    "    from sklearn.manifold import TSNE\n",
    "#     print('CE Model: TSNE')\n",
    "    embedding = TSNE(n_components=2, perplexity=30, n_iter=1000)\n",
    "    X_CE = embedding.fit_transform(X)\n",
    "    print(f'TSNE\\tOld shape = {X.shape}\\t\\t new shape = {X_CE.shape}\\t\\t components = {n}')\n",
    "    return X_CE\n",
    "\n",
    "\n",
    "\n",
    "def CFS(X, y, n=2):\n",
    "#     print('CFS Model')\n",
    "    selector = SelectKBest(score_func=f_regression, k=5)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    return X_new\n",
    "\n",
    "def LLCFS(X, y=None,n=2):\n",
    "#     print('LLCFS Model')\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def ILFS(X, y):\n",
    "    # create a linear regression model\n",
    "#     print('ILFS Model')\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # define the search space\n",
    "    k_features = np.arange(1, X.shape[1]+1)\n",
    "    \n",
    "    # create a sequential feature selector object\n",
    "    selector = SequentialFeatureSelector(model, k_features=k_features, forward=True, scoring='r2', cv=5)\n",
    "    \n",
    "    # perform incremental feature selection\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "    # print the selected feature indices\n",
    "    print(\"Indices of selected features:\", selector.k_feature_idx_)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9250ece6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nX1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9972\\2147822876.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# for lol in range(2, nX1.shape[1]):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mNoF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;31m# Number of features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mX1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoF\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mDR\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# dimension reduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mresults1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX1s\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Machine learning models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nX1' is not defined"
     ]
    }
   ],
   "source": [
    "# performing experiment 2    \n",
    "\n",
    "DR = [ CFS, LLCFS, PCA_model, CE_Model, CE2, LLE, Isomap, TSNE,]\n",
    "DR_TXT = [ 'CFS', 'LLCFS', 'PCA_model', 'CE_Model', 'CE2', 'LLE', 'Isomap', 'TSNE', ]\n",
    "\n",
    "# for lol in range(2, nX1.shape[1]):\n",
    "\n",
    "NoF = nX1.shape[1]-3 # Number of features\n",
    "X1s = [d(X1, np.ravel(Y1), NoF) for d in DR] # dimension reduction\n",
    "results1 = [predict(x1, np.ravel(Y1)) for x1 in X1s] # Machine learning models\n",
    "\n",
    "finals = []\n",
    "for i in range(len(DR)):\n",
    "    rd = DR_TXT[i]\n",
    "    print(rd)\n",
    "    acc, sen, spe = [],[],[]\n",
    "    for a, s, e in results1[i]:\n",
    "        acc.append(a)\n",
    "        sen.append(s)\n",
    "        spe.append(e)\n",
    "    finals.append(pd.DataFrame({'model': predictorsTXT,'accuracy': acc, 'sensitivity': sen, 'specificity': spe}))\n",
    "\n",
    "\n",
    "finalR = {}\n",
    "for i in predictorsTXT:\n",
    "    D = pd.DataFrame() # create an empty DataFrame to hold the filtered rows     \n",
    "    for df in finals:\n",
    "        row = df[df['model'] == i]\n",
    "        D = D.append(row) # filter rows that match a certain condition and append them to D\n",
    "    D['DR'] = DR_TXT\n",
    "    D = D.drop('model', axis=1)\n",
    "    finalR[i] = D\n",
    "\n",
    "for i in finalR:\n",
    "    print(i)\n",
    "    print(finalR[i][['DR', 'accuracy' , 'sensitivity',  'specificity']])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e23cabc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nX2 = stats.zscore(X2)\n",
    "\n",
    "NoF = nX2.shape[1]-3 # Number of features\n",
    "X2s = [d(X2, np.ravel(Y2), NoF) for d in DR]\n",
    "\n",
    "results2 = [predict(x2, np.ravel(Y2)) for x2 in X2s]\n",
    "finals = []\n",
    "for i in range(len(DR)):\n",
    "    rd = DR_TXT[i]\n",
    "    acc, sen, spe = [],[],[]\n",
    "    for a, s, e in results2[i]:\n",
    "        acc.append(a)\n",
    "        sen.append(s)\n",
    "        spe.append(e)\n",
    "    finals.append(pd.DataFrame({'model': predictorsTXT,'accuracy': acc, 'sensitivity': sen, 'specificity': spe}))\n",
    "    \n",
    "    \n",
    "finalR = {}\n",
    "for i in predictorsTXT:\n",
    "    D = pd.DataFrame() # create an empty DataFrame to hold the filtered rows     \n",
    "    for df in finals:\n",
    "        row = df[df['model'] == i]\n",
    "        D = D.append(row) # filter rows that match a certain condition and append them to D\n",
    "    D['DR'] = DR_TXT\n",
    "    D = D.drop('model', axis=1)\n",
    "    finalR[i] = D\n",
    "\n",
    "for i in finalR:\n",
    "    print(i)\n",
    "    print(finalR[i][['DR', 'accuracy' , 'sensitivity',  'specificity']])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
